{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d33596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "# %pip uninstall TA-Lib\n",
    "# %pip uninstall numpy\n",
    "\n",
    "\n",
    "# filepath: c:\\Users\\mahme\\trading_bot\\notebooks\\train_lstm.ipynb\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94afb427",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57c6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.data_fetch import connect_mt5, fetch_symbol_data\n",
    "from src.features import (add_RSI_EMA, add_ATR, add_candlestick_patterns,\n",
    "                          add_VSA_signals_refined, detect_order_blocks,create_sequences)\n",
    "\n",
    "\n",
    "# 1. Fetch or load CSV\n",
    "df = pd.read_csv(\"data/XAUUSD_M5.csv\", parse_dates=[\"time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f385aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----- Cell: Compute Indicators -----\n",
    "import talib\n",
    "\n",
    "df = pd.read_csv(\"data/XAUUSD_M5.csv\", parse_dates=[\"time\"])\n",
    "df = add_RSI_EMA(df, rsi_period=14, ema_periods=[20, 50])\n",
    "df = add_ATR(df, atr_period=14)\n",
    "\n",
    "# 1. Compute per-bar 14-period ATR (if not already present)\n",
    "df[\"ATR_14\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "\n",
    "# 2. Compute next bar’s percentage change\n",
    "df[\"next_pct_change\"] = (df[\"Close\"].shift(-1) - df[\"Close\"]) / df[\"Close\"]\n",
    "\n",
    "# 3. Define threshold = 0.5 × (ATR / Close)\n",
    "df[\"threshold\"] = 0.5 * (df[\"ATR_14\"] / df[\"Close\"])\n",
    "\n",
    "# 4. Define a function to label Up/Down/Hold\n",
    "def label_with_hold(row):\n",
    "    change = row[\"next_pct_change\"]\n",
    "    thr    = row[\"threshold\"]\n",
    "    if abs(change) <= thr:\n",
    "        return 2   # Hold (no significant move)\n",
    "    elif change > thr:\n",
    "        return 1   # Up\n",
    "    else:\n",
    "        return 0   # Down\n",
    "\n",
    "# 5. Apply the function to create a 3-class label\n",
    "df[\"Direction3\"] = df.apply(label_with_hold, axis=1)\n",
    "# -----------------------------------------\n",
    "\n",
    "df = add_candlestick_patterns(df)\n",
    "df = add_VSA_signals_refined(df)\n",
    "df = detect_order_blocks(df)\n",
    "# -----------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b8199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahme\\AppData\\Local\\Temp\\ipykernel_47896\\2090988042.py:18: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df[\"H1_timefloor\"] = df[\"time\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 2.3: Load H1 and compute its RSI, EMA, ATR\n",
    "df_h1 = pd.read_csv(\"data/XAUUSD_H1.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "# 2.3.1 Compute H1 indicators exactly as for M5\n",
    "df_h1 = add_RSI_EMA(df_h1,  rsi_period=14, ema_periods=[50, 100])\n",
    "df_h1 = add_ATR(df_h1,     atr_period=14)\n",
    "\n",
    "# 2.3.2 Keep only the columns we need from H1\n",
    "df_h1 = df_h1[[\"time\", \"RSI\", \"EMA_50\", \"ATR\"]].rename(columns={\n",
    "    \"RSI\": \"H1_RSI\",\n",
    "    \"EMA_50\": \"H1_EMA_50\",\n",
    "    \"ATR\": \"H1_ATR\"\n",
    "})\n",
    "\n",
    "# 2.3.3 For each M5 bar, find the most recent H1 bar (floor to the hour)\n",
    "# Create a column that floors M5 time to the preceding hour\n",
    "df[\"H1_timefloor\"] = df[\"time\"].dt.floor(\"H\")\n",
    "\n",
    "# 2.3.4 Merge H1 onto M5 by matching the floored time\n",
    "df = df.merge(\n",
    "    df_h1,\n",
    "    left_on=\"H1_timefloor\",\n",
    "    right_on=\"time\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_h1\")\n",
    ")\n",
    "\n",
    "# 2.3.5 Clean up: drop the extra columns\n",
    "df.drop(columns=[\"time_h1\", \"H1_timefloor\"], inplace=True)\n",
    "# -----------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e237e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after H1 merge: ['time', 'Open', 'High', 'Low', 'Close', 'Volume', 'RSI', 'EMA_20', 'EMA_50', 'ATR', 'ATR_14', 'next_pct_change', 'threshold', 'Direction3', 'HAMMER', 'ENGULFING', 'DOJI', 'vsa_signal', 'VSA_No_Demand', 'VSA_No_Supply', 'VSA_Buying_Climax', 'VSA_Selling_Climax', 'VSA_Stopping_Volume', 'OB_type', 'OB_price', 'H1_RSI', 'H1_EMA_50', 'H1_ATR']\n",
      "Sample rows with H1 features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Close</th>\n",
       "      <th>H1_RSI</th>\n",
       "      <th>H1_EMA_50</th>\n",
       "      <th>H1_ATR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-21 08:10:00</td>\n",
       "      <td>2928.79</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-21 08:15:00</td>\n",
       "      <td>2927.93</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-21 08:20:00</td>\n",
       "      <td>2927.89</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-21 08:25:00</td>\n",
       "      <td>2928.77</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-21 08:30:00</td>\n",
       "      <td>2930.80</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-02-21 08:35:00</td>\n",
       "      <td>2930.33</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-02-21 08:40:00</td>\n",
       "      <td>2929.42</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-02-21 08:45:00</td>\n",
       "      <td>2929.48</td>\n",
       "      <td>42.792434</td>\n",
       "      <td>2934.764935</td>\n",
       "      <td>8.449047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    Close     H1_RSI    H1_EMA_50    H1_ATR\n",
       "0 2025-02-21 08:10:00  2928.79  42.792434  2934.764935  8.449047\n",
       "1 2025-02-21 08:15:00  2927.93  42.792434  2934.764935  8.449047\n",
       "2 2025-02-21 08:20:00  2927.89  42.792434  2934.764935  8.449047\n",
       "3 2025-02-21 08:25:00  2928.77  42.792434  2934.764935  8.449047\n",
       "4 2025-02-21 08:30:00  2930.80  42.792434  2934.764935  8.449047\n",
       "5 2025-02-21 08:35:00  2930.33  42.792434  2934.764935  8.449047\n",
       "6 2025-02-21 08:40:00  2929.42  42.792434  2934.764935  8.449047\n",
       "7 2025-02-21 08:45:00  2929.48  42.792434  2934.764935  8.449047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts (should be minimal after dropping):\n",
      "H1_RSI       0\n",
      "H1_EMA_50    0\n",
      "H1_ATR       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 2.4: Quick sanity check\n",
    "print(\"Columns after H1 merge:\", df.columns.tolist())\n",
    "print(\"Sample rows with H1 features:\")\n",
    "display(df[[\"time\", \"Close\", \"H1_RSI\", \"H1_EMA_50\", \"H1_ATR\"]].head(8))\n",
    "print(\"NaN counts (should be minimal after dropping):\")\n",
    "print(df[[\"H1_RSI\", \"H1_EMA_50\", \"H1_ATR\"]].isna().sum())\n",
    "# -----------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4bb157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-H1-merge 3-class distribution (%):\n",
      "Series([], Name: proportion, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 2.5: Drop any NaNs (including H1 columns) and reset index\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 2.5.1: Inspect new 3-class distribution (optional; may be unchanged)\n",
    "dist3     = df[\"Direction3\"].value_counts(normalize=True) * 100\n",
    "print(\"Post-H1-merge 3-class distribution (%):\")\n",
    "print(dist3)\n",
    "\n",
    "# 2.5.2: Split into train/val chronologically (80/20)\n",
    "train_size = int(len(df) * 0.8)\n",
    "df_train   = df.iloc[:train_size].copy()\n",
    "df_val     = df.iloc[train_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85219245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40fda504",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['OB_bullish', 'OB_bearish', 'Distance_to_OB'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m lookback  = \u001b[32m60\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 2.5.4: Re-create sequences with new features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m X_train, y_train, scaler = \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m X_val,   y_val,   _      = create_sequences(df_val,   feature_cols, label_col, lookback)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNew shapes including H1 features:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahme\\trading_bot\\src\\features.py:208\u001b[39m, in \u001b[36mcreate_sequences\u001b[39m\u001b[34m(df, feature_cols, label_col, lookback)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03mBuild normalized sequences for LSTM input.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m- feature_cols: list of feature column names\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03mReturns: X (num_samples, lookback, num_features), y (num_samples,), scaler (fitted MinMaxScaler)\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Extract feature matrix and labels\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m data = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m.values.astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    209\u001b[39m labels = df[label_col].values.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    211\u001b[39m scaler = MinMaxScaler(feature_range=(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mahme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['OB_bullish', 'OB_bearish', 'Distance_to_OB'] not in index\""
     ]
    }
   ],
   "source": [
    "# 2.5.3: Re-define feature_cols (add H1 features)\n",
    "feature_cols = [\n",
    "    \"Close\", \"RSI\",       \"EMA_20\",   \"EMA_50\",  \"ATR\",\n",
    "    \"H1_RSI\", \"H1_EMA_50\",\"H1_ATR\",\n",
    "    # ... plus whatever VSA/OB one-hot columns you have, e.g.:\n",
    "    \"VSA_No_Demand\", \"VSA_No_Supply\", \"VSA_Buying_Climax\",\n",
    "    \"VSA_Selling_Climax\", \"VSA_Stopping_Volume\",\n",
    "    \"OB_bullish\", \"OB_bearish\", \"Distance_to_OB\"\n",
    "]\n",
    "\n",
    "label_col = \"Direction3\"\n",
    "lookback  = 60\n",
    "\n",
    "# 2.5.4: Re-create sequences with new features\n",
    "X_train, y_train, scaler = create_sequences(df_train, feature_cols, label_col, lookback)\n",
    "X_val,   y_val,   _      = create_sequences(df_val,   feature_cols, label_col, lookback)\n",
    "\n",
    "print(\"New shapes including H1 features:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val  :\", X_val.shape,   \"y_val  :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6300b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15927, 60, 5) y_train shape: (15927,)\n",
      "X_val   shape: (3936, 60, 5) y_val   shape: (3936,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lookback = 60\n",
    "X_train, y_train, scaler = create_sequences(df_train, feature_cols, label_col, lookback)\n",
    "X_val,   y_val,   _      = create_sequences(df_val,   feature_cols, label_col, lookback)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_val   shape:\", X_val.shape,   \"y_val   shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71362b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,091</span> (473.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,091\u001b[0m (473.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,643</span> (471.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,643\u001b[0m (471.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- New Model Cell -----\n",
    "# 1) Import our build function\n",
    "from src.model_lstm import build_3class_lstm_model\n",
    "\n",
    "# 2) Define input_shape based on X_train\n",
    "#    X_train.shape == (num_samples, lookback, num_features)\n",
    "lookback     = X_train.shape[1]\n",
    "num_features = X_train.shape[2]\n",
    "input_shape  = (lookback, num_features)\n",
    "\n",
    "# 3) Build and compile\n",
    "model = build_3class_lstm_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# 4) (Optional) If you want to save a reference to the best model:\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"models/lstm_best.h5\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22016919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5822 - loss: 1.1734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 62ms/step - accuracy: 0.5823 - loss: 1.1731 - val_accuracy: 0.6087 - val_loss: 1.0772\n",
      "Epoch 2/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6046 - loss: 1.0664 - val_accuracy: 0.6087 - val_loss: 1.0486\n",
      "Epoch 3/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6041 - loss: 1.0427 - val_accuracy: 0.6087 - val_loss: 1.0244\n",
      "Epoch 4/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - accuracy: 0.6063 - loss: 1.0195 - val_accuracy: 0.6087 - val_loss: 1.0025\n",
      "Epoch 5/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - accuracy: 0.6005 - loss: 1.0019 - val_accuracy: 0.6087 - val_loss: 0.9834\n",
      "Epoch 6/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.6041 - loss: 0.9826 - val_accuracy: 0.6087 - val_loss: 0.9678\n"
     ]
    }
   ],
   "source": [
    "# ----- New Training Cell -----\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,            # or more, with EarlyStopping\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
